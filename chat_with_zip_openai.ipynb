{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKHi4MrnDR40tRC6Rbr3zK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiekVerhoeff/workshop/blob/main/chat_with_zip_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chat with your files - OpenAI**\n",
        "\n",
        "This notebook demonstrates a Retreival Augmented Generation system that can read data from different files zipped in a zip-file.\n",
        "\n",
        "For this notebook you need an OpenAI API KEY. If your using Colab, you can set an environmentvariable with the name OPENAI_API_KEY in the secrets menu. You can find the secrets menu under the key symbol on the left."
      ],
      "metadata": {
        "id": "y6y7SeiMPXN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting things up\n",
        "\n",
        "First we need to install some packages. Then we can upload a zip-file to the Colab. After that we import packages, libraries and secrets. If you haven't given this Colab access to your secrets, it will ask for it when you execute Initialize things. Finally in this stage you will read the files and embed the textdata into nodes."
      ],
      "metadata": {
        "id": "Nrbt57RiIn4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize things\n",
        "\n",
        "!pip install llama-index\n",
        "!pip install docx2txt\n",
        "#!pip install torch transformers python-pptx Pillow\n",
        "%pip install llama-index-readers-web\n",
        "%pip install llama-index-program-openai\n",
        "%pip install llama-index-llms-openai\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from typing import Dict\n",
        "from typing import Any\n",
        "from llama_index.program.openai import OpenAIPydanticProgram\n",
        "from llama_index.core.extractors import PydanticProgramExtractor\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.llms.openai import OpenAI"
      ],
      "metadata": {
        "id": "LlUgWBs4FvoJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6mGSHSOQIZyb"
      },
      "outputs": [],
      "source": [
        "#@title Upload a zip-file with documents\n",
        "#@markdown supported extensions are listed here: https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload the ZIP file\n",
        "uploaded = files.upload()  # Select and upload the ZIP file\n",
        "\n",
        "# Assuming there's only one ZIP file uploaded, get its filename\n",
        "zip_filename = next(iter(uploaded.keys()))\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "print(\"Folder structure has been extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load data\n",
        "\n",
        "# @markdown If you're working in Colab, go to the files menu by clicking the folder symbol on the left. Right click (or click on the three dots) on the folder you uploaded and choose Copy Path (Pad kopiÃ«ren) and paste below. Check the recursive box if the given directory has subdirectories.\n",
        "\n",
        "directory = '/content/bronnen_in_bytes'#@param {type:\"string\"}\n",
        "\n",
        "reader = SimpleDirectoryReader(\n",
        "    input_dir=f\"{directory}\",\n",
        "    recursive=False # @param {type:\"boolean\"}\n",
        ")\n",
        "\n",
        "all_docs = []\n",
        "\n",
        "for docs in reader.iter_data():\n",
        "    for doc in docs:\n",
        "        doc.text = doc.text.upper()\n",
        "        print(doc.text)\n",
        "        all_docs.append(doc)\n",
        "\n",
        "print(len(all_docs))"
      ],
      "metadata": {
        "id": "XoVpLx3RKtmz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chat Away!\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "index = VectorStoreIndex.from_documents(all_docs)\n",
        "\n",
        "chat_engine = index.as_chat_engine(chat_mode=\"best\", llm=llm, verbose=True)\n",
        "\n",
        "prompt = \"Wat is er met het Gemeenteblad gebeurd?\" #@param {type:\"string\"}\n",
        "\n",
        "response = chat_engine.chat(\n",
        "    prompt\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LAsqJSooiRsV"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}