{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdShvbNp8dS/Fn5GyeKrTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiekVerhoeff/workshop/blob/main/rag_on_zipfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install packages\n",
        "\n",
        "!pip install llama-index\n",
        "!pip install docx2txt\n",
        "!pip install torch transformers python-pptx Pillow\n",
        "%pip install llama-index-readers-web\n",
        "%pip install llama-index-program-openai"
      ],
      "metadata": {
        "id": "LlUgWBs4FvoJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6mGSHSOQIZyb"
      },
      "outputs": [],
      "source": [
        "#@title Upload a zipfile with documents\n",
        "#@markdown supported extensions are: .txt .csv .xml .pdf .docx .pptx\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload the ZIP file\n",
        "uploaded = files.upload()  # Select and upload the ZIP file\n",
        "\n",
        "# Assuming there's only one ZIP file uploaded, get its filename\n",
        "zip_filename = next(iter(uploaded.keys()))\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "print(\"Folder structure has been extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize things\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from typing import Dict\n",
        "from llama_index.program.openai import OpenAIPydanticProgram\n",
        "from llama_index.core.extractors import PydanticProgramExtractor\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "from llama_index.core.ingestion import IngestionPipeline"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GD8-qfrRF5JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load data\n",
        "\n",
        "reader = SimpleDirectoryReader(\n",
        "    input_dir=\"./test_colab_upload\",\n",
        "    recursive=True,\n",
        ")\n",
        "\n",
        "reader2 = SimpleDirectoryReader(\n",
        "    input_dir=\"./test_colab_upload\",\n",
        "    recursive=False,\n",
        ")\n",
        "\n",
        "all_docs = []\n",
        "\n",
        "for docs in reader2.iter_data():\n",
        "    for doc in docs:\n",
        "        # do something with the doc\n",
        "        doc.text = doc.text.upper()\n",
        "        all_docs.append(doc)\n",
        "\n",
        "for docs in reader.iter_data():\n",
        "    for doc in docs:\n",
        "        # do something with the doc\n",
        "        doc.text = doc.text.upper()\n",
        "        all_docs.append(doc)\n",
        "\n",
        "print(len(all_docs))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XoVpLx3RKtmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define extracted elements\n",
        "\n",
        "#@markdown\n",
        "\n",
        "class NodeMetadata(BaseModel):\n",
        "    \"\"\"Node metadata.\"\"\"\n",
        "\n",
        "    entities: List[str] = Field(\n",
        "        ..., description=\"Maak voor iedere entiteit in dit stuk tekst een string in de vorm van een valide python dicrionary waarbij je de entiteit als value neemt en een key verzint. Entiteiten die van eenzelfe type zijn, geef je dezelfde key\"\n",
        "    )\n",
        "    description: str = Field(\n",
        "        ..., description=\"Maak een archiefbeschrijving van dit stuk tekst\"\n",
        "    )\n",
        "    contains_number: bool = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Whether the text chunk contains any numbers (ints, floats, etc.)\"\n",
        "        ),\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "q_E4SkZ_PKuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from llama_index.program.openai import OpenAIPydanticProgram\n",
        "#from llama_index.core.extractors import PydanticProgramExtractor\n",
        "#@title Setup extractor\n",
        "EXTRACT_TEMPLATE_STR = \"\"\"\\\n",
        "Here is the content of the section:\n",
        "----------------\n",
        "{context_str}\n",
        "----------------\n",
        "Given the contextual information, extract out a {class_name} object.\\\n",
        "\"\"\"\n",
        "\n",
        "openai_program = OpenAIPydanticProgram.from_defaults(\n",
        "    output_cls=NodeMetadata,\n",
        "    prompt_template_str=\"{input}\",\n",
        "    # extract_template_str=EXTRACT_TEMPLATE_STR\n",
        ")\n",
        "\n",
        "program_extractor = PydanticProgramExtractor(\n",
        "    program=openai_program, input_key=\"input\", show_progress=True\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jVeu_oNqPdwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "#from llama_index.core.ingestion import IngestionPipeline\n",
        "#@title Extract away!\n",
        "\n",
        "node_parser = SentenceSplitter(chunk_size=1024)\n",
        "\n",
        "pipeline = IngestionPipeline(transformations=[node_parser, program_extractor])\n",
        "\n",
        "\n",
        "orig_nodes = pipeline.run(documents=all_docs)\n",
        "sample_entry = program_extractor.extract(orig_nodes)\n",
        "display(sample_entry)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n71qUGrZPkru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}